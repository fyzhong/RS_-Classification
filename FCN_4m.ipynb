{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from FCN4m_model import *\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_path,label_path,batch_size = 30):\n",
    "    row = 256\n",
    "    col = 256\n",
    "    imagenames = []\n",
    "    labelnames = []\n",
    "    for i in os.listdir(image_path):\n",
    "        imagenames.append(i)\n",
    "    for i in os.listdir(label_path):\n",
    "        labelnames.append(i)\n",
    "    while 1:\n",
    "        num_batch = len(imagenames)//batch_size\n",
    "\n",
    "#         image_path = r'G:\\rssrai2019_semantic_segmentation\\train\\image_clip'\n",
    "#         label_path = r'G:\\rssrai2019_semantic_segmentation\\train\\pro_label'\n",
    "\n",
    "        for i in range(num_batch):\n",
    "            image_datas = np.zeros((batch_size,row,col,4),dtype = np.float)\n",
    "            label_datas = np.zeros((batch_size,row,col,16),dtype = np.float)\n",
    "            for j in range(batch_size):\n",
    "                imagename = os.path.join(image_path,imagenames[i*batch_size + j])\n",
    "#                 print('imagenames:'+imagenames[i*batch_size + j])\n",
    "                image_datas[j,::,::,::] = np.load(imagename)/255.0\n",
    "                labelname = os.path.join(label_path,labelnames[i*batch_size + j])\n",
    "#                 print('labelname:'+labelnames[i*batch_size + j])\n",
    "                label_data = to_categorical(np.load(labelname),16)\n",
    "                label_datas[j,:,:,:] = label_data\n",
    "#                 label_data = np.load(labelname)\n",
    "#                 for k in range(16):\n",
    "#                     label_datas[j,label_data == k,k] =1\n",
    "            yield image_datas,label_datas\n",
    "            image_datas = np.zeros((batch_size,row,col,4),dtype = np.float)\n",
    "            label_datas = np.zeros((batch_size,row,col,16),dtype = np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.shape:(?, 256, 256, 64)\n",
      "pool1.shape:(?, 128, 128, 64)\n",
      "conv2.shape:(?, 128, 128, 128)\n",
      "conv3.shape:(?, 64, 64, 256)\n",
      "conv4.shape:(?, 32, 32, 512)\n",
      "conv5.shape:(?, 16, 16, 1024)\n",
      "conv6.shape:(?, 32, 32, 512)\n",
      "conv7.shape:(?, 64, 64, 256)\n",
      "conv8.shape:(?, 128, 128, 128)\n",
      "conv9.shape:(?, 256, 256, 32)\n",
      "conv10.shape:(?, 256, 256, 16)\n",
      "starttime: 2019-07-01 14:39:07.770632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LUCC_do\\FCN4m_model.py:70: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1566/1566 [==============================] - 1031s 658ms/step - loss: 1.0689 - categorical_accuracy: 0.6344 - val_loss: 8.1978 - val_categorical_accuracy: 0.3665\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.06894, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 2/200\n",
      "1566/1566 [==============================] - 1022s 653ms/step - loss: 1.0364 - categorical_accuracy: 0.6497 - val_loss: 7.3139 - val_categorical_accuracy: 0.3574\n",
      "\n",
      "Epoch 00002: loss improved from 1.06894 to 1.03637, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 3/200\n",
      "1566/1566 [==============================] - 1022s 653ms/step - loss: 0.9831 - categorical_accuracy: 0.6725 - val_loss: 7.3505 - val_categorical_accuracy: 0.3736\n",
      "\n",
      "Epoch 00003: loss improved from 1.03637 to 0.98311, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 4/200\n",
      "1566/1566 [==============================] - 1022s 653ms/step - loss: 0.9556 - categorical_accuracy: 0.6763 - val_loss: 6.1342 - val_categorical_accuracy: 0.3622\n",
      "\n",
      "Epoch 00004: loss improved from 0.98311 to 0.95561, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 5/200\n",
      "1566/1566 [==============================] - 1021s 652ms/step - loss: 0.8950 - categorical_accuracy: 0.6974 - val_loss: 6.3156 - val_categorical_accuracy: 0.3570\n",
      "\n",
      "Epoch 00005: loss improved from 0.95561 to 0.89497, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 6/200\n",
      "1566/1566 [==============================] - 1032s 659ms/step - loss: 0.8766 - categorical_accuracy: 0.7023 - val_loss: 6.6774 - val_categorical_accuracy: 0.3638\n",
      "\n",
      "Epoch 00006: loss improved from 0.89497 to 0.87658, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 7/200\n",
      "1566/1566 [==============================] - 1040s 664ms/step - loss: 0.8556 - categorical_accuracy: 0.7071 - val_loss: 5.9948 - val_categorical_accuracy: 0.3561\n",
      "\n",
      "Epoch 00007: loss improved from 0.87658 to 0.85563, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 8/200\n",
      "1566/1566 [==============================] - 1032s 659ms/step - loss: 0.8238 - categorical_accuracy: 0.7176 - val_loss: 6.3795 - val_categorical_accuracy: 0.3675\n",
      "\n",
      "Epoch 00008: loss improved from 0.85563 to 0.82383, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 9/200\n",
      "1566/1566 [==============================] - 1023s 654ms/step - loss: 0.7838 - categorical_accuracy: 0.7271 - val_loss: 5.7530 - val_categorical_accuracy: 0.3761\n",
      "\n",
      "Epoch 00009: loss improved from 0.82383 to 0.78384, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 10/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.7818 - categorical_accuracy: 0.7313 - val_loss: 6.1694 - val_categorical_accuracy: 0.3728\n",
      "\n",
      "Epoch 00010: loss improved from 0.78384 to 0.78177, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 11/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.7572 - categorical_accuracy: 0.7373 - val_loss: 6.3269 - val_categorical_accuracy: 0.3818\n",
      "\n",
      "Epoch 00011: loss improved from 0.78177 to 0.75718, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 12/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.7416 - categorical_accuracy: 0.7371 - val_loss: 5.4905 - val_categorical_accuracy: 0.3874\n",
      "\n",
      "Epoch 00012: loss improved from 0.75718 to 0.74163, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 13/200\n",
      "1566/1566 [==============================] - 1017s 650ms/step - loss: 0.7341 - categorical_accuracy: 0.7379 - val_loss: 5.4014 - val_categorical_accuracy: 0.3452\n",
      "\n",
      "Epoch 00013: loss improved from 0.74163 to 0.73413, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 14/200\n",
      "1566/1566 [==============================] - 1016s 649ms/step - loss: 0.7250 - categorical_accuracy: 0.7422 - val_loss: 5.8085 - val_categorical_accuracy: 0.3545\n",
      "\n",
      "Epoch 00014: loss improved from 0.73413 to 0.72499, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 15/200\n",
      "1566/1566 [==============================] - 1016s 649ms/step - loss: 0.7121 - categorical_accuracy: 0.7463 - val_loss: 5.9393 - val_categorical_accuracy: 0.3542\n",
      "\n",
      "Epoch 00015: loss improved from 0.72499 to 0.71208, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 16/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.6949 - categorical_accuracy: 0.7534 - val_loss: 5.1741 - val_categorical_accuracy: 0.3651\n",
      "\n",
      "Epoch 00016: loss improved from 0.71208 to 0.69491, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 17/200\n",
      "1566/1566 [==============================] - 1019s 650ms/step - loss: 0.6890 - categorical_accuracy: 0.7553 - val_loss: 4.7106 - val_categorical_accuracy: 0.3876\n",
      "\n",
      "Epoch 00017: loss improved from 0.69491 to 0.68902, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 18/200\n",
      "1566/1566 [==============================] - 1019s 650ms/step - loss: 0.6677 - categorical_accuracy: 0.7627 - val_loss: 5.4973 - val_categorical_accuracy: 0.3985\n",
      "\n",
      "Epoch 00018: loss improved from 0.68902 to 0.66773, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 19/200\n",
      "1566/1566 [==============================] - 1017s 650ms/step - loss: 0.6420 - categorical_accuracy: 0.7688 - val_loss: 4.9680 - val_categorical_accuracy: 0.4239\n",
      "\n",
      "Epoch 00019: loss improved from 0.66773 to 0.64201, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 20/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.6267 - categorical_accuracy: 0.7756 - val_loss: 4.9992 - val_categorical_accuracy: 0.4180\n",
      "\n",
      "Epoch 00020: loss improved from 0.64201 to 0.62674, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 21/200\n",
      "1566/1566 [==============================] - 1019s 650ms/step - loss: 0.6193 - categorical_accuracy: 0.7766 - val_loss: 5.4955 - val_categorical_accuracy: 0.4187\n",
      "\n",
      "Epoch 00021: loss improved from 0.62674 to 0.61930, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 22/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.6202 - categorical_accuracy: 0.7771 - val_loss: 5.6296 - val_categorical_accuracy: 0.4177\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.61930\n",
      "Epoch 23/200\n",
      "1566/1566 [==============================] - 1019s 650ms/step - loss: 0.6121 - categorical_accuracy: 0.7794 - val_loss: 5.9182 - val_categorical_accuracy: 0.4155\n",
      "\n",
      "Epoch 00023: loss improved from 0.61930 to 0.61211, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 24/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.6041 - categorical_accuracy: 0.7814 - val_loss: 5.9868 - val_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00024: loss improved from 0.61211 to 0.60410, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 25/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5932 - categorical_accuracy: 0.7860 - val_loss: 5.3268 - val_categorical_accuracy: 0.3981\n",
      "\n",
      "Epoch 00025: loss improved from 0.60410 to 0.59318, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 26/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5951 - categorical_accuracy: 0.7858 - val_loss: 5.6033 - val_categorical_accuracy: 0.3937\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.59318\n",
      "Epoch 27/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5873 - categorical_accuracy: 0.7904 - val_loss: 6.1056 - val_categorical_accuracy: 0.3904\n",
      "\n",
      "Epoch 00027: loss improved from 0.59318 to 0.58734, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 28/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5833 - categorical_accuracy: 0.7917 - val_loss: 4.7831 - val_categorical_accuracy: 0.3787\n",
      "\n",
      "Epoch 00028: loss improved from 0.58734 to 0.58333, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 29/200\n",
      "1566/1566 [==============================] - 1019s 650ms/step - loss: 0.5695 - categorical_accuracy: 0.7960 - val_loss: 4.9529 - val_categorical_accuracy: 0.3911\n",
      "\n",
      "Epoch 00029: loss improved from 0.58333 to 0.56950, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 30/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.5516 - categorical_accuracy: 0.8013 - val_loss: 5.9407 - val_categorical_accuracy: 0.3942\n",
      "\n",
      "Epoch 00030: loss improved from 0.56950 to 0.55162, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 31/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.5516 - categorical_accuracy: 0.8021 - val_loss: 5.0222 - val_categorical_accuracy: 0.3966\n",
      "\n",
      "Epoch 00031: loss improved from 0.55162 to 0.55159, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 32/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.5501 - categorical_accuracy: 0.8021 - val_loss: 4.8602 - val_categorical_accuracy: 0.3974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: loss improved from 0.55159 to 0.55011, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 33/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5450 - categorical_accuracy: 0.8038 - val_loss: 4.8098 - val_categorical_accuracy: 0.3861\n",
      "\n",
      "Epoch 00033: loss improved from 0.55011 to 0.54504, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 34/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.5475 - categorical_accuracy: 0.8039 - val_loss: 4.8370 - val_categorical_accuracy: 0.3884\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.54504\n",
      "Epoch 35/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5243 - categorical_accuracy: 0.8101 - val_loss: 4.8319 - val_categorical_accuracy: 0.3887\n",
      "\n",
      "Epoch 00035: loss improved from 0.54504 to 0.52427, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 36/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5127 - categorical_accuracy: 0.8149 - val_loss: 5.5630 - val_categorical_accuracy: 0.4067\n",
      "\n",
      "Epoch 00036: loss improved from 0.52427 to 0.51268, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 37/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.5001 - categorical_accuracy: 0.8182 - val_loss: 5.0049 - val_categorical_accuracy: 0.4169\n",
      "\n",
      "Epoch 00037: loss improved from 0.51268 to 0.50007, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 38/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.4803 - categorical_accuracy: 0.8247 - val_loss: 5.3120 - val_categorical_accuracy: 0.3905\n",
      "\n",
      "Epoch 00038: loss improved from 0.50007 to 0.48030, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 39/200\n",
      "1566/1566 [==============================] - 1017s 650ms/step - loss: 0.4569 - categorical_accuracy: 0.8328 - val_loss: 5.5861 - val_categorical_accuracy: 0.4129\n",
      "\n",
      "Epoch 00039: loss improved from 0.48030 to 0.45685, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 40/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.4410 - categorical_accuracy: 0.8389 - val_loss: 4.8676 - val_categorical_accuracy: 0.4130\n",
      "\n",
      "Epoch 00040: loss improved from 0.45685 to 0.44099, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 41/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.4417 - categorical_accuracy: 0.8395 - val_loss: 5.1262 - val_categorical_accuracy: 0.4129\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.44099\n",
      "Epoch 42/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.4257 - categorical_accuracy: 0.8442 - val_loss: 4.8158 - val_categorical_accuracy: 0.4284\n",
      "\n",
      "Epoch 00042: loss improved from 0.44099 to 0.42570, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 43/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.4206 - categorical_accuracy: 0.8476 - val_loss: 5.0526 - val_categorical_accuracy: 0.4325\n",
      "\n",
      "Epoch 00043: loss improved from 0.42570 to 0.42063, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 44/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.3914 - categorical_accuracy: 0.8576 - val_loss: 5.0615 - val_categorical_accuracy: 0.4273\n",
      "\n",
      "Epoch 00044: loss improved from 0.42063 to 0.39138, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 45/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.3728 - categorical_accuracy: 0.8649 - val_loss: 5.5925 - val_categorical_accuracy: 0.4280\n",
      "\n",
      "Epoch 00045: loss improved from 0.39138 to 0.37275, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 46/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.3553 - categorical_accuracy: 0.8712 - val_loss: 5.1138 - val_categorical_accuracy: 0.4337\n",
      "\n",
      "Epoch 00046: loss improved from 0.37275 to 0.35530, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 47/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.3483 - categorical_accuracy: 0.8740 - val_loss: 5.0519 - val_categorical_accuracy: 0.4324\n",
      "\n",
      "Epoch 00047: loss improved from 0.35530 to 0.34828, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 48/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.3382 - categorical_accuracy: 0.8771 - val_loss: 4.8600 - val_categorical_accuracy: 0.4389\n",
      "\n",
      "Epoch 00048: loss improved from 0.34828 to 0.33821, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 49/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.3312 - categorical_accuracy: 0.8806 - val_loss: 5.2986 - val_categorical_accuracy: 0.4328\n",
      "\n",
      "Epoch 00049: loss improved from 0.33821 to 0.33118, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 50/200\n",
      "1566/1566 [==============================] - 1018s 650ms/step - loss: 0.3227 - categorical_accuracy: 0.8838 - val_loss: 5.1815 - val_categorical_accuracy: 0.4477\n",
      "\n",
      "Epoch 00050: loss improved from 0.33118 to 0.32273, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 51/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.3117 - categorical_accuracy: 0.8872 - val_loss: 5.1399 - val_categorical_accuracy: 0.4451\n",
      "\n",
      "Epoch 00051: loss improved from 0.32273 to 0.31172, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 52/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.2969 - categorical_accuracy: 0.8924 - val_loss: 4.9160 - val_categorical_accuracy: 0.4467\n",
      "\n",
      "Epoch 00052: loss improved from 0.31172 to 0.29692, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 53/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.2906 - categorical_accuracy: 0.8945 - val_loss: 5.4175 - val_categorical_accuracy: 0.4472\n",
      "\n",
      "Epoch 00053: loss improved from 0.29692 to 0.29057, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 54/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.2811 - categorical_accuracy: 0.8979 - val_loss: 5.0507 - val_categorical_accuracy: 0.4596\n",
      "\n",
      "Epoch 00054: loss improved from 0.29057 to 0.28113, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 55/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.2735 - categorical_accuracy: 0.9006 - val_loss: 5.1294 - val_categorical_accuracy: 0.4487\n",
      "\n",
      "Epoch 00055: loss improved from 0.28113 to 0.27349, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 56/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.2616 - categorical_accuracy: 0.9052 - val_loss: 5.3147 - val_categorical_accuracy: 0.4464\n",
      "\n",
      "Epoch 00056: loss improved from 0.27349 to 0.26161, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 57/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.2650 - categorical_accuracy: 0.9037 - val_loss: 4.9351 - val_categorical_accuracy: 0.4603\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.26161\n",
      "Epoch 58/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.2469 - categorical_accuracy: 0.9094 - val_loss: 5.1941 - val_categorical_accuracy: 0.4583\n",
      "\n",
      "Epoch 00058: loss improved from 0.26161 to 0.24691, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 59/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.2431 - categorical_accuracy: 0.9115 - val_loss: 5.6947 - val_categorical_accuracy: 0.4573\n",
      "\n",
      "Epoch 00059: loss improved from 0.24691 to 0.24313, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 60/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.2436 - categorical_accuracy: 0.9116 - val_loss: 5.7310 - val_categorical_accuracy: 0.4585\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.24313\n",
      "Epoch 61/200\n",
      "1566/1566 [==============================] - 1019s 651ms/step - loss: 0.2288 - categorical_accuracy: 0.9166 - val_loss: 5.6730 - val_categorical_accuracy: 0.4493\n",
      "\n",
      "Epoch 00061: loss improved from 0.24313 to 0.22882, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 62/200\n",
      "1566/1566 [==============================] - 1017s 650ms/step - loss: 0.2312 - categorical_accuracy: 0.9157 - val_loss: 5.8044 - val_categorical_accuracy: 0.4538\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.22882\n",
      "Epoch 63/200\n",
      "1566/1566 [==============================] - 1017s 649ms/step - loss: 0.2161 - categorical_accuracy: 0.9212 - val_loss: 5.4994 - val_categorical_accuracy: 0.4617\n",
      "\n",
      "Epoch 00063: loss improved from 0.22882 to 0.21610, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 64/200\n",
      "1566/1566 [==============================] - 1016s 649ms/step - loss: 0.2145 - categorical_accuracy: 0.9220 - val_loss: 5.2354 - val_categorical_accuracy: 0.4568\n",
      "\n",
      "Epoch 00064: loss improved from 0.21610 to 0.21448, saving model to log\\FCN_4m_701.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "1566/1566 [==============================] - 1017s 649ms/step - loss: 0.2051 - categorical_accuracy: 0.9252 - val_loss: 5.4594 - val_categorical_accuracy: 0.4646\n",
      "\n",
      "Epoch 00065: loss improved from 0.21448 to 0.20512, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 66/200\n",
      "1566/1566 [==============================] - 1020s 651ms/step - loss: 0.1987 - categorical_accuracy: 0.9271 - val_loss: 5.5133 - val_categorical_accuracy: 0.4602\n",
      "\n",
      "Epoch 00066: loss improved from 0.20512 to 0.19875, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 67/200\n",
      "1566/1566 [==============================] - 1024s 654ms/step - loss: 0.1941 - categorical_accuracy: 0.9286 - val_loss: 5.8541 - val_categorical_accuracy: 0.4609\n",
      "\n",
      "Epoch 00067: loss improved from 0.19875 to 0.19411, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 68/200\n",
      "1566/1566 [==============================] - 1022s 653ms/step - loss: 0.1985 - categorical_accuracy: 0.9277 - val_loss: 5.6692 - val_categorical_accuracy: 0.4623\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.19411\n",
      "Epoch 69/200\n",
      "1566/1566 [==============================] - 1022s 652ms/step - loss: 0.1881 - categorical_accuracy: 0.9308 - val_loss: 5.5955 - val_categorical_accuracy: 0.4635\n",
      "\n",
      "Epoch 00069: loss improved from 0.19411 to 0.18814, saving model to log\\FCN_4m_701.h5\n",
      "Epoch 70/200\n",
      " 105/1566 [=>............................] - ETA: 14:35 - loss: 0.2843 - categorical_accuracy: 0.8962"
     ]
    }
   ],
   "source": [
    "model = unet()\n",
    "# 设置运行时间\n",
    "import datetime\n",
    "starttime = datetime.datetime.now()\n",
    "print('starttime:',starttime)\n",
    "image_path = r'G:\\rssrai2019_semantic_segmentation\\train\\image_clip'\n",
    "label_path = r'G:\\rssrai2019_semantic_segmentation\\train\\pro_label'\n",
    "\n",
    "vali_image_path = r'G:\\rssrai2019_semantic_segmentation\\val\\image_clip'\n",
    "vali_label_path = r'G:\\rssrai2019_semantic_segmentation\\val\\pro_label'\n",
    "# Tensorboard可视化\n",
    "tensorboards = keras.callbacks.TensorBoard(log_dir = './log',histogram_freq = 0,batch_size = 4,write_graph = True,write_grads = False,write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "Model_checkpoints  = ModelCheckpoint(filepath='log\\\\FCN_4m_701.h5', monitor='loss',verbose=1,save_best_only='True',mode='auto',period=1)\n",
    "callbacks = [tensorboards,Model_checkpoints]\n",
    "# 训练网络\n",
    "model.fit_generator(generator = generate_data(image_path = image_path,label_path = label_path,batch_size = 4),validation_data = generate_data(image_path = vali_image_path,label_path = vali_label_path,batch_size = 2),validation_steps=783,max_queue_size=1,steps_per_epoch = 1566,epochs = 200,verbose=1,callbacks = callbacks)\n",
    "model.evaluate_generator(generate_data(image_path = vali_image_path,label_path = vali_label_path,batch_size = 2),steps = 783,verbose = 1)\n",
    "endtime = datetime.datetime.now()\n",
    "print('endtime:',endtime)\n",
    "times = endtime - starttime\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
